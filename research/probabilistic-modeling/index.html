<!DOCTYPE html> <html lang=""> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> probabilistic and generative modeling | Jongha Jon Ryu </title> <meta name="author" content="Jongha Jon Ryu"> <meta name="description" content="# A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="Jongha Ryu, J. Jon Ryu, 류종하"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jongharyu.github.io/research/probabilistic-modeling/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Jongha <span class="font-weight-bold">Jon</span> Ryu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item active"> <a class="nav-link" href="/research/">research <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">probabilistic and generative modeling</h1> <p class="post-description"></p> </header> <article> <h2 id="overview">overview</h2> <p>Probabilistic and generative modeling are core components of statistical inference and modern machine learning, supporting tasks such as representation learning, scientific data modeling, and structured prediction. I develop probabilistic and generative modeling methods grounded in first principles, including divergence minimization and density-ratio estimation with statistical guarantees. The goal is to design learning objectives that are stable, interpretable, and effective in high-dimensional scientific settings, while offering a unified view of methods that are often studied separately.</p> <p>Below are some recent works in this direction.</p> <h3 id="score-of-mixture-training-for-one-step-generative-models-1">score-of-mixture training for one-step generative models <a class="citation" href="#Jayashankar--Ryu--Wornell2025">[1]</a> </h3> <p>Recent advances in diffusion modeling aim to reduce sampling complexity while maintaining high sample quality. In <a class="citation" href="#Jayashankar--Ryu--Wornell2025">[1]</a>, we introduce the Score-of-Mixture framework, a new formulation for training one-step score-based generative models based on statistical divergence minimization. The method uses score estimation for gradient evaluation during training, and achieves stable optimization and state-of-the-art sample quality.</p> <div class="text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/research/smt_overview-480.webp 480w,/assets/img/research/smt_overview-800.webp 800w,/assets/img/research/smt_overview-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/research/smt_overview.png" class="img-fluid rounded z-depth-1 w-75" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <h3 id="unifying-and-improving-contrastive-learning-principles">unifying and improving contrastive learning principles</h3> <h4 id="1-unified-learning-principles-for-energy-based-models-2">(1) unified learning principles for energy-based models <a class="citation" href="#Ryu--Shah--Wornell2025">[2]</a> </h4> <p>Energy-based models are expressive and broadly used in generative modeling, causal inference, and computational physics, but are difficult to train due to the unknown partition function. In <a class="citation" href="#Ryu--Shah--Wornell2025">[2]</a>, we provide a unified analysis of many existing estimators through noise contrastive estimation within a Bregman divergence framework. This perspective clarifies connections among methods, provides statistical consistency guarantees, and identifies common failure modes.</p> <div class="text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/icml2025b-480.webp 480w,/assets/img/publication_preview/icml2025b-800.webp 800w,/assets/img/publication_preview/icml2025b-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/publication_preview/icml2025b.png" class="img-fluid rounded z-depth-1 w-50" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <h4 id="2-consistent-neural-density-ratio-estimation-3">(2) consistent neural density-ratio estimation <a class="citation" href="#Ryu--Yeddanapudi--Xu--Wornell2025">[3]</a> </h4> <p>InfoNCE is widely used for representation learning, yet its relationship to mutual information has remained unclear.<br> In <a class="citation" href="#Ryu--Yeddanapudi--Xu--Wornell2025">[3]</a>, we demystify the InfoNCE objective by providing the sharp information-theoretic characterization of the objective, and introduce a simple correction that resolves this issue, yielding consistent density-ratio and mutual-information estimation. This provides a principled basis for ratio-based learning across various downstream tasks in machine learning.</p> <div class="text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/infonce-480.webp 480w,/assets/img/publication_preview/infonce-800.webp 800w,/assets/img/publication_preview/infonce-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/publication_preview/infonce.png" class="img-fluid rounded z-depth-1 w-75" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <h2 id="broader-perspective">broader perspective</h2> <p>These probabilistic tools support a range of modeling tasks, including score-based generative modeling for scientific data, energy-based formulations for structured prediction, and ratio-based training for representation learning and distribution estimation.</p> <p>Probabilistic and generative modeling connect modern deep learning with classical ideas in <strong>statistics</strong>, <strong>information theory</strong>, and <strong>stochastic processes</strong>. Ongoing work includes:</p> <ul> <li>developing score-based models aligned with operator and spectral structure,</li> <li>integrating ratio-based learning with uncertainty quantification,</li> <li>and applying these methods to scientific inverse problems and simulation pipelines.</li> </ul> </article> <h2>references</h2> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row pub-entry" data-keywords="probabilistic-modeling,deep-learning,information-theory,information-measures,divergence-matching" data-selected="true"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00369f"> <a href="https://icml.cc/" rel="external nofollow noopener" target="_blank">ICML</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/icml2025a.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icml2025a.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Jayashankar--Ryu--Wornell2025" class="col-sm-8"> <div class="title">Score-of-Mixture Training: Training One-Step Generative Models Made Simple</div> <div class="author"> <a href="https://tejasjayashankar.github.io/" rel="external nofollow noopener" target="_blank">Tejas Jayashankar<sup>*</sup></a>, <em>J. Jon Ryu<sup>*</sup></em>, and <a href="http://allegro.mit.edu/~gww/" rel="external nofollow noopener" target="_blank">Gregory W. Wornell</a> </div> <div class="periodical"> <em>In ICML</em>, July 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Spotlight</a> <div class="tldr"> <strong>TL;DR:</strong> We propose a new method for training one-step generative models by minimizing the α-skew Jensen–Shannon divergence using score-based gradient estimates. </div> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2502.09609" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="/assets/pdf/icml2025a.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/tkj516/score-of-mixture-training" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/icml2025-smt-poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Top 2.6% of submissions</p> </div> <div class="abstract hidden"> <p>We propose Score-of-Mixture Training (SMT), a novel framework for training one-step generative models by minimizing a class of divergences called the α-skew Jensen-Shannon divergence. At its core, SMT estimates the score of mixture distributions between real and fake samples across multiple noise levels. Similar to consistency models, our approach supports both training from scratch (SMT) and distillation using a pretrained diffusion model, which we call Score-of-Mixture Distillation (SMD). It is simple to implement, requires minimal hyperparameter tuning, and ensures stable training. Experiments on CIFAR-10 and ImageNet 64x64 show that SMT/SMD are competitive with and can even outperform existing methods.</p> </div> </div> </div> </li> <li> <div class="row pub-entry" data-keywords="probabilistic-modeling,statistics,divergence-matching" data-selected="true"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00369f"> <a href="https://icml.cc/" rel="external nofollow noopener" target="_blank">ICML</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/icml2025b.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icml2025b.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Ryu--Shah--Wornell2025" class="col-sm-8"> <div class="title">A Unified View on Learning Unnormalized Distributions via Noise-Contrastive Estimation</div> <div class="author"> <em>J. Jon Ryu</em>, <a href="https://abhin-shah.github.io/" rel="external nofollow noopener" target="_blank">Abhin Shah</a>, and <a href="http://allegro.mit.edu/~gww/" rel="external nofollow noopener" target="_blank">Gregory W. Wornell</a> </div> <div class="periodical"> <em>In ICML</em>, July 2025 </div> <div class="periodical"> </div> <div class="links"> <div class="tldr"> <strong>TL;DR:</strong> We provide a unified perspective on various methods for learning unnormalized distributions through the lens of noise-contrastive estimation. </div> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2409.18209" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="/assets/pdf/icml2025b.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/icml2025-nce-poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>This paper studies a family of estimators based on noise-contrastive estimation (NCE) for learning unnormalized distributions. The main contribution of this work is to provide a unified perspective on various methods for learning unnormalized distributions, which have been independently proposed and studied in separate research communities, through the lens of NCE. This unified view offers new insights into existing estimators. Specifically, for exponential families, we establish the finite-sample convergence rates of the proposed estimators under a set of regularity assumptions, most of which are new.</p> </div> </div> </div> </li> <li> <div class="row pub-entry" data-keywords="probabilistic-modeling,information-theory,information-measures,divergence-matching" data-selected="true"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#a1a1a1"> <a href="https://arxiv.org/" rel="external nofollow noopener" target="_blank">arXiv</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/infonce.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="infonce.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Ryu--Yeddanapudi--Xu--Wornell2025" class="col-sm-8"> <div class="title">Contrastive Predictive Coding Done Right for Mutual Information Estimation</div> <div class="author"> <em>J. Jon Ryu</em>, Pavan Yeddanapudi, <a href="https://xiangxiangxu.mit.edu/" rel="external nofollow noopener" target="_blank">Xiangxiang Xu</a>, and <a href="http://allegro.mit.edu/~gww/" rel="external nofollow noopener" target="_blank">Gregory W. Wornell</a> </div> <div class="periodical"> October 2025 </div> <div class="periodical"> </div> <div class="links"> <div class="tldr"> <strong>TL;DR:</strong> We show that InfoNCE is an inconsistent MI estimator, and introduce a minimal modification that enables consistent density-ratio estimation and accurate MI estimation. </div> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2510.25983" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>The InfoNCE objective, originally introduced for contrastive representation learning, has become a popular choice for mutual information (MI) estimation, despite its indirect connection to MI. In this paper, we demonstrate why InfoNCE should not be regarded as a valid MI estimator, and we introduce a simple modification, which we refer to as InfoNCE-anchor, for accurate MI estimation. Our modification introduces an auxiliary anchor class, enabling consistent density ratio estimation and yielding a plug-in MI estimator with significantly reduced bias. Beyond this, we generalize our framework using proper scoring rules, which recover InfoNCE-anchor as a special case when the log score is employed. This formulation unifies a broad spectrum of contrastive objectives, including NCE, InfoNCE, and f-divergence variants, under a single principled framework. Empirically, we find that InfoNCE-anchor with the log score achieves the most accurate MI estimates; however, in self-supervised representation learning experiments, we find that the anchor does not improve the downstream task performance. These findings corroborate that contrastive representation learning benefits not from accurate MI estimation per se, but from the learning of structured density ratios.</p> </div> </div> </div> </li> </ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jongha Jon Ryu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: December 17, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-3M2EMEPQ20"></script> <script defer src="/assets/js/google-analytics-setup.js"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>