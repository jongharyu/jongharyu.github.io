<!DOCTYPE html> <html lang=""> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> uncertainty quantification | Jongha Jon Ryu </title> <meta name="author" content="Jongha Jon Ryu"> <meta name="description" content="# A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="Jongha Ryu, J. Jon Ryu, 류종하"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jongharyu.github.io/research/uncertainty-quantification/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Jongha <span class="font-weight-bold">Jon</span> Ryu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item active"> <a class="nav-link" href="/research/">research <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">uncertainty quantification</h1> <p class="post-description"></p> </header> <article> <h2 id="overview">overview</h2> <p>To apply ML techniques to scientific and engineering systems, we require reliable uncertainty estimates. Models must quantify uncertainty, detect distribution shift, and support adaptive decision making, yet many uncertainty quantification (UQ) techniques in deep learning remain ad hoc. Often, classical methods do not scale, and heuristic approaches behave unpredictably in safety-critical environments such as control, robotics, and adaptive sensing.</p> <p>My work approaches UQ along two complementary fronts:</p> <ol> <li> <strong>theoretical tools for anytime-valid and sequential decision making</strong>, and</li> <li> <strong>practical diagnostics and corrections for empirical UQ methods in large models</strong>.</li> </ol> <h2 id="information-theoretic-anytime-valid-inference">information-theoretic anytime-valid inference</h2> <p>Many scientific and engineering tasks operate in sequential or adaptive settings where fixed-time uncertainty bounds fail. Using ideas from universal coding and gambling, I develop <strong>confidence sequences</strong> (CSs) that provide time-uniform uncertainty guarantees. These results strengthen classical concentration bounds and support sequential decisiom making problems such as A/B testing and contextual bandits.</p> <p>This line of work establishes the power of information-theoretic constructions of confidence sequences, including:</p> <ul> <li>confidence sequences for bounded variables <a class="citation" href="#Ryu--Bhatt2024">[1]</a>,</li> <li>confidence sequences for bounded vectors <a class="citation" href="#Ryu--Wornell2024">[2]</a>, and</li> <li>confidence sequences for semi-unbounded variables <a class="citation" href="#Ryu--Kwon--Koppe--Jun2025">[3]</a>, which have applications in offline bandit problems.</li> </ul> <h2 id="diagnosing-empirical-uq">diagnosing empirical UQ</h2> <p>There are many proposals for scalable uncertainty quantification in large neural predictive models, yet their statistical meanings and failure modes often remain unclear. In <a class="citation" href="#Shen--Ryu--Ghosh--Bu--Sattigeri--Das--Wornell2024">[4]</a>, we analyze <strong>evidential deep learning</strong> and show that its uncertainty targets do not correspond to the underlying data distribution, contrary to the original interpretation. This explains its inconsistent empirical behavior and highlights structural issues in commonly used heuristic UQ pipelines. These findings motivate the need for uncertainty quantification methods that remain meaningful and reliable even in large-scale or misspecified regimes.</p> <h2 id="broader-perspective">broader perspective</h2> <p>These theoretical and empirical perspectives support reliable decision making in systems such as data-driven control, safe autonomy, adaptive sensing, and scientific inference. Ongoing work includes:</p> <ul> <li>extending confidence sequence techniques to operator-valued settings such as streaming PCA,</li> <li>integrating time-uniform UQ with operator learning and generative modeling,</li> <li>and designing UQ frameworks that scale to large models with provable reliability guarantees.</li> </ul> <p>These tools aim to provide the foundations for uncertainty-aware scientific and engineering workflows, where reliable decisions depend on trustworthy uncertainty estimates.</p> </article> <h2>references</h2> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"><li> <div class="row pub-entry" data-keywords="uncertainty-quantification,information-theory,sequential-decision-making,statistics" data-selected="true"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00369f"> <a href="https://learningtheory.org/" rel="external nofollow noopener" target="_blank">COLT</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/colt2025.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="colt2025.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Ryu--Kwon--Koppe--Jun2025" class="col-sm-8"> <div class="title">Improved Offline Contextual Bandits with Second-Order Bounds: Betting and Freezing</div> <div class="author"> <em>J. Jon Ryu</em>, <a href="https://kwonchungli.github.io/" rel="external nofollow noopener" target="_blank">Jeongyeol Kwon</a>, Benjamin Koppe, and <a href="https://kwangsungjun.github.io/" rel="external nofollow noopener" target="_blank">Kwang-Sung Jun</a> </div> <div class="periodical"> <em>In COLT</em>, June 2025 </div> <div class="periodical"> </div> <div class="links"> <div class="tldr"> <strong>TL;DR:</strong> We introduce a betting-based confidence bound for off-policy selection, and a new off-policy learning technique that provides a favorable bias-variance tradeoff. </div> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2502.10826" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="/assets/pdf/colt2025.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/jongharyu/confidence-sequence-via-gambling" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We consider off-policy selection and learning in contextual bandits, where the learner aims to select or train a reward-maximizing policy using data collected by a fixed behavior policy. Our contribution is two-fold. First, we propose a novel off-policy selection method that leverages a new betting-based confidence bound applied to an inverse propensity weight sequence. Our theoretical analysis reveals that this method achieves a significantly improved, variance-adaptive guarantee over prior work. Second, we propose a novel and generic condition on the optimization objective for off-policy learning that strikes a different balance between bias and variance. One special case, which we call freezing, tends to induce low variance, which is preferred in small-data regimes. Our analysis shows that it matches the best existing guarantees. In our empirical study, our selection method outperforms existing methods, and freezing exhibits improved performance in small-sample regimes.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row pub-entry" data-keywords="sequential-decision-making,uncertainty-quantification,information-theory,statistics" data-selected="true"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff6f00"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=18" rel="external nofollow noopener" target="_blank">TransIT</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/tit2024.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tit2024.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Ryu--Bhatt2024" class="col-sm-8"> <div class="title">On Confidence Sequences for Bounded Random Processes via Universal Gambling Strategies</div> <div class="author"> <em>J. Jon Ryu</em> and <a href="https://alankritabhatt.github.io/" rel="external nofollow noopener" target="_blank">Alankrita Bhatt</a> </div> <div class="periodical"> <em>IEEE TransIT</em>, June 2024 </div> <div class="periodical"> </div> <div class="links"> <div class="tldr"> <strong>TL;DR:</strong> We provide a simple two-horse-race perspective for constructing confidence sequences for bounded random processes, demonstrate new properties of the confidence sequence induced by universal portfolio, and propose its computationally efficient relaxations. </div> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2207.12382" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://ieeexplore.ieee.org/document/10645704" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/tit2024.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/jongharyu/confidence-sequence-via-gambling" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>This paper considers the problem of constructing a confidence sequence, which is a sequence of confidence intervals that hold uniformly over time, for estimating the mean of bounded real-valued random processes. This paper revisits the gambling-based approach established in the recent literature from a natural \emphtwo-horse race perspective, and demonstrates new properties of the resulting algorithm induced by Cover (1991)’s universal portfolio. The main result of this paper is a new algorithm based on a mixture of lower bounds, which closely approximates the performance of Cover’s universal portfolio with constant per-round time complexity. A higher-order generalization of a lower bound on a logarithmic function in (Fan et al., 2015), which is developed as a key technique for the proposed algorithm, may be of independent interest.</p> </div> </div> </div> </li> <li> <div class="row pub-entry" data-keywords="sequential-decision-making,uncertainty-quantification,information-theory,statistics" data-selected="true"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00369f"> <a href="https://icml.cc/" rel="external nofollow noopener" target="_blank">ICML</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/icml2024b.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icml2024b.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Ryu--Wornell2024" class="col-sm-8"> <div class="title">Gambling-Based Confidence Sequences for Bounded Random Vectors</div> <div class="author"> <em>J. Jon Ryu</em> and <a href="http://allegro.mit.edu/~gww/" rel="external nofollow noopener" target="_blank">Gregory W. Wornell</a> </div> <div class="periodical"> <em>In ICML</em>, July 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Spotlight</a> <div class="tldr"> <strong>TL;DR:</strong> We propose a new approach to constructing confidence sequences for means of bounded multivariate stochastic processes using a general gambling framework. </div> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2402.03683" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openreview.net/forum?id=mu7Er7f9NQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/icml2024b.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/jongharyu/confidence-sequence-via-gambling" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/icml2024-gambling-poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Top 3.5% of submissions</p> </div> <div class="abstract hidden"> <p>A confidence sequence (CS) is a sequence of confidence sets that contains a target parameter of an underlying stochastic process at any time step with high probability. This paper proposes a new approach to constructing CSs for means of bounded multivariate stochastic processes using a general gambling framework, extending the recently established coin toss framework for bounded random processes. The proposed gambling framework provides a general recipe for constructing CSs for categorical and probability-vector-valued observations, as well as for general bounded multidimensional observations through a simple reduction. This paper specifically explores the use of the mixture portfolio, akin to Cover’s universal portfolio, in the proposed framework and investigates the properties of the resulting CSs. Simulations demonstrate the tightness of these confidence sequences compared to existing methods. When applied to the sampling without-replacement setting for finite categorical data, it is shown that the resulting CS based on a universal gambling strategy is provably tighter than that of the posterior-prior ratio martingale proposed by Waudby-Smith and Ramdas.</p> </div> </div> </div> </li> <li> <div class="row pub-entry" data-keywords="uncertainty-quantification,deep-learning,divergence-matching" data-selected="false"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00369f"> <a href="https://neurips.cc/" rel="external nofollow noopener" target="_blank">NeurIPS</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/neurips2024.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="neurips2024.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Shen--Ryu--Ghosh--Bu--Sattigeri--Das--Wornell2024" class="col-sm-8"> <div class="title">Are Uncertainty Quantification Capabilities of Evidential Deep Learning a Mirage?</div> <div class="author"> <a href="https://maohaos2.github.io/Maohao/" rel="external nofollow noopener" target="_blank">Maohao Shen<sup>*</sup></a>, <em>J. Jon Ryu<sup>*</sup></em>, Soumya Ghosh, <a href="https://buyuheng.github.io/" rel="external nofollow noopener" target="_blank">Yuheng Bu</a>, Prasanna Sattigeri, Subhro Das, and <a href="http://allegro.mit.edu/~gww/" rel="external nofollow noopener" target="_blank">Gregory W. Wornell</a> </div> <div class="periodical"> <em>In NeurIPS</em>, December 2024 </div> <div class="periodical"> </div> <div class="links"> <div class="tldr"> <strong>TL;DR:</strong> We theoretically characterize the pitfalls of evidential deep learning (EDL) in quantifying predictive uncertainty by unifying various EDL objective functions, and empirically demonstrate their failure modes. </div> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2402.06160" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openreview.net/forum?id=P6nVDZRZRB" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/neurips2024.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/maohaos2/EDL-Mirage" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/neurips2024-poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="/assets/pdf/talks/neurips2024-slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>This paper questions the effectiveness of a modern predictive uncertainty quantification approach, called \emphevidential deep learning (EDL), in which a single neural network model is trained to learn a meta distribution over the predictive distribution by minimizing a specific objective function. Despite their perceived strong empirical performance on downstream tasks, a line of recent studies by Bengs et al. identify limitations of the existing methods to conclude their learned epistemic uncertainties are unreliable, e.g., in that they are non-vanishing even with infinite data. Building on and sharpening such analysis, we 1) provide a sharper understanding of the asymptotic behavior of a wide class of EDL methods by unifying various objective functions; 2) reveal that the EDL methods can be better interpreted as an out-of-distribution detection algorithm based on energy-based-models; and 3) conduct extensive ablation studies to better assess their empirical effectiveness with real-world datasets. Through all these analyses, we conclude that even when EDL methods are empirically effective on downstream tasks, this occurs despite their poor uncertainty quantification capabilities. Our investigation suggests that incorporating model uncertainty can help EDL methods faithfully quantify uncertainties and further improve performance on representative downstream tasks, albeit at the cost of additional computational complexity.</p> </div> </div> </div> </li> </ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jongha Jon Ryu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: December 16, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-3M2EMEPQ20"></script> <script defer src="/assets/js/google-analytics-setup.js"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>