---
layout: about
title: About
permalink: /
subtitle: Postdoctoral Associate at MIT

profile:
  align: right
  image: jon.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>Room 36-677</p>
    <p>50 Vassar St</p>
    <p>Cambridge, MA 02139</p>

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

[//]: # '[//]: <span style="font-weight:bold"><mark>'
[//]: # "[//]: "
[//]: # "[//]: </mark></span>"

I am currently a postdoctoral associate at MIT, hosted by [Gregory W. Wornell](http://allegro.mit.edu/~gww/).
Prior to joining MIT, I received my Ph.D. in [Electrical Engineering](https://ece.ucsd.edu/) from [UC San Diego](https://ucsd.edu/),
where I was fortunate to be advised by [Young-Han Kim](https://web.eng.ucsd.edu/~yhk/) and [Sanjoy Dasgupta](https://cseweb.ucsd.edu/~dasgupta/).
My graduate study was generously supported by the [Kwanjeong Educational Foundation](http://www.ikef.or.kr/).
Before the graduate study, I received my B.S. in [Electrical and Computer Engineering](https://ece.snu.ac.kr/en) and B.S. in [Mathematical Sciences](https://www.math.snu.ac.kr/) (with minor in [Physics](https://physics.snu.ac.kr/en)) with the highest distinction from [Seoul National University](https://en.snu.ac.kr) in 2015.

In general, I aim to develop principled and practical algorithms for machine learning and data science.
My recent research topics include:

- **neural-net-based methods for large-scale spectral decomposition problems** ([NeuralSVD [ICML2024]](http://arxiv.org/abs/2402.03655))
- **representation learning** 
  - structured representation learning ([NeuralSVD [ICML2024]](http://arxiv.org/abs/2402.03655))
  - information-theoretic common representation learning ([variational Wyner model [arXiv]](http://arxiv.org/abs/1905.10945))
  - [fast kernel embedding without EVD [ISIT2021]](https://ieeexplore.ieee.org/document/9517746)
- **sequential decision making / online learning**
  - from universal gambling to time-uniform confidence sets [[TIT2024]](http://arxiv.org/abs/2207.12382), [[ICML2024]](http://arxiv.org/abs/2402.03683)
  - from universal gambling to parameter-free online learning [[AISTATS2022]](http://arxiv.org/abs/2202.02406)
- **learning with small-k-nearest neighbors** 
  - unified view on density functional estimation with fixed-k-NNs [[TIT2022]](http://arxiv.org/abs/1805.08342)
  - minimax-optimal classification, regression, density estimation with distributed fixed-k-NNs [[arXiv]](http://arxiv.org/abs/2202.02464)
- **learning uncertainty for black-box model predictions**
  - demystifying the empirical successes of evidential deep learning [[NeurIPS2024](http://arxiv.org/abs/2402.06160)]

As an information theorist by training, I enjoy doing research by simplifying intricate ideas, unifying concepts, and generalizing them to address complex problems.

Check out my [resume](/resume) for more information.
