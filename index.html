<!DOCTYPE html> <html lang=""> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Jongha Jon Ryu </title> <meta name="author" content="Jongha Jon Ryu"> <meta name="description" content="# A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jongharyu.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%6A%6F%6E%67%68%61.%72%79%75@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=5ZYeWgcAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/jongharyu" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/jongha-jon-ryu-997ba7a7" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/resume/">resume </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Jongha <span class="font-weight-bold">Jon</span> Ryu </h1> <p class="desc">Postdoctoral Associate at MIT</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/jon-480.webp 480w,/assets/img/jon-800.webp 800w,/assets/img/jon-1400.webp 1400w," sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/jon.jpg?426407e770f1c3b18dcddff81a1f58b7" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="jon.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>Room 36-677</p> <p>50 Vassar St</p> <p>Cambridge, MA 02139</p> </div> </div> <div class="clearfix"> <p>I am currently a postdoctoral associate at MIT, hosted by <a href="http://allegro.mit.edu/~gww/" rel="external nofollow noopener" target="_blank">Gregory W. Wornell</a>. Prior to joining MIT, I received my Ph.D. in <a href="https://ece.ucsd.edu/" rel="external nofollow noopener" target="_blank">Electrical Engineering</a> from <a href="https://ucsd.edu/" rel="external nofollow noopener" target="_blank">UC San Diego</a>, where I was fortunate to be advised by <a href="https://web.eng.ucsd.edu/~yhk/" rel="external nofollow noopener" target="_blank">Young-Han Kim</a> and <a href="https://cseweb.ucsd.edu/~dasgupta/" rel="external nofollow noopener" target="_blank">Sanjoy Dasgupta</a>. My graduate study was generously supported by the <a href="http://www.ikef.or.kr/" rel="external nofollow noopener" target="_blank">Kwanjeong Educational Foundation</a>. Before the graduate study, I received my B.S. in <a href="https://ece.snu.ac.kr/en" rel="external nofollow noopener" target="_blank">Electrical and Computer Engineering</a> and B.S. in <a href="https://www.math.snu.ac.kr/" rel="external nofollow noopener" target="_blank">Mathematical Sciences</a> (with minor in <a href="https://physics.snu.ac.kr/en" rel="external nofollow noopener" target="_blank">Physics</a>) with the highest distinction from <a href="https://en.snu.ac.kr" rel="external nofollow noopener" target="_blank">Seoul National University</a> in 2015.</p> <p>I am interested in a broad range of topics related to learning from data, both in theory and practice. My recent research focuses on:</p> <ul> <li> <strong>New machine learning techniques for scalable scientific simulation</strong> <ul> <li>a parametric framework for operator SVD (<a href="http://arxiv.org/abs/2402.03655" rel="external nofollow noopener" target="_blank">NeuralSVD [ICML2024a]</a>)</li> <li>variations and applications (work in progress)</li> </ul> </li> <li> <strong>New techniques for probabilistic (generative) models</strong> <ul> <li>an efficient framework for training one-step, high-quality generative models (<a href="https://arxiv.org/abs/2502.09609" rel="external nofollow noopener" target="_blank">Score-of-Mixture Training [ICML2025a]</a>)</li> <li>unifying principles for learning with energy-based models [<a href="http://arxiv.org/abs/2409.18209" rel="external nofollow noopener" target="_blank">ICML2025b</a>]</li> </ul> </li> <li> <strong>New techniques and perspectives for uncertainty quantification</strong> <ul> <li>universal gambling-based time-uniform confidence sets <a href="http://arxiv.org/abs/2207.12382" rel="external nofollow noopener" target="_blank">[TIT2024]</a>, <a href="http://arxiv.org/abs/2402.03683" rel="external nofollow noopener" target="_blank">[ICML2024b]</a>, and applications <a href="https://arxiv.org/abs/2502.10826" rel="external nofollow noopener" target="_blank">[arXiv2025b]</a> </li> <li>identifying pitfalls of evidential deep learning [<a href="http://arxiv.org/abs/2402.06160" rel="external nofollow noopener" target="_blank">NeurIPS2024</a>]</li> </ul> </li> </ul> <p>As an information theorist by training, I enjoy doing research by simplifying intricate ideas, unifying concepts, and generalizing them to address complex problems.</p> <p>Check out my <a href="/resume">resume</a> for more information.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">May 01, 2025</th> <td> Two papers, <a href="https://arxiv.org/abs/2502.09609" rel="external nofollow noopener" target="_blank">Score-of-Mixture Training</a> (<strong>Spotlight</strong>, top 2.6%) and <a href="https://arxiv.org/abs/2409.18209" rel="external nofollow noopener" target="_blank">unifying principles of fitting energy-based models</a>, accepted at ICML 2025! </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 19, 2025</th> <td> New paper alerts! We propose: (1) a new simple and stable training scheme for one-step generative models <a href="https://arxiv.org/abs/2502.09609" rel="external nofollow noopener" target="_blank">(paper1)</a>; (2) new techniques for efficient off-policy contextual bandits <a href="https://arxiv.org/abs/2502.10826" rel="external nofollow noopener" target="_blank">(paper2)</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 23, 2024</th> <td> In this fall, I have given talks on <a href="https://openreview.net/forum?id=qESG5HaaoJ" rel="external nofollow noopener" target="_blank">NeuralSVD</a> at MERL, KAIST, KIAS, and Flatiron Institute. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 25, 2024</th> <td> Our paper on <a href="http://arxiv.org/abs/2402.06160" rel="external nofollow noopener" target="_blank">demystifying the sucess of evidential deep learning methods</a> got accepted at NeurIPS 2024! </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 06, 2024</th> <td> I have posted a substantially revised version of the <a href="https://arxiv.org/abs/2202.02464" rel="external nofollow noopener" target="_blank">arXiv preprint</a> on minimax optimal learning with fixed-k-nearest neighbors, now including new results on density estimation. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TIT</abbr> </div> <div id="Ryu--Ganguly--Kim--Noh--Lee2018" class="col-sm-8"> <div class="title">Nearest neighbor density functional estimation from inverse Laplace transform</div> <div class="author"> <em>J. Jon Ryu*</em>, <a href="https://acsweb.ucsd.edu/~shgangul/" rel="external nofollow noopener" target="_blank">Shouvik Ganguly*</a>, <a href="https://web.eng.ucsd.edu/~yhk/" rel="external nofollow noopener" target="_blank">Young-Han Kim</a>, <a href="http://aais.hanyang.ac.kr/nohyung/" rel="external nofollow noopener" target="_blank">Yung-Kyun Noh</a>, and <a href="https://www.ece.cornell.edu/faculty-directory/daniel-dongyuel-lee" rel="external nofollow noopener" target="_blank">Daniel D. Lee</a> </div> <div class="periodical"> <em>IEEE Trans. Inf. Theory</em>, February 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/1805.08342" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://ieeexplore.ieee.org/document/9712283" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/tit2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/jongharyu/knn-functional-estimation" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>A new approach to L_2-consistent estimation of a general density functional using k-nearest neighbor distances is proposed, where the functional under consideration is in the form of the expectation of some function f of the densities at each point. The estimator is designed to be asymptotically unbiased, using the convergence of the normalized volume of a k-nearest neighbor ball to a Gamma distribution in the large-sample limit, and naturally involves the inverse Laplace transform of a scaled version of the function f. Some instantiations of the proposed estimator recover existing k-nearest neighbor based estimators of Shannon and Rényi entropies and Kullback–Leibler and Rényi divergences, and discover new consistent estimators for many other functionals such as logarithmic entropies and divergences. The L_2-consistency of the proposed estimator is established for a broad class of densities for general functionals, and the convergence rate in mean squared error is established as a function of the sample size for smooth, bounded densities.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TIT</abbr> </div> <div id="Ryu--Bhatt2024" class="col-sm-8"> <div class="title">On Confidence Sequences for Bounded Random Processes via Universal Gambling Strategies</div> <div class="author"> <em>J. Jon Ryu</em>, and <a href="https://alankritabhatt.github.io/" rel="external nofollow noopener" target="_blank">Alankrita Bhatt</a> </div> <div class="periodical"> <em>IEEE Trans. Inf. Theory</em>, February 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2207.12382" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="/assets/html/" class="btn btn-sm z-depth-0" role="button">HTML</a> <a href="https://github.com/jongharyu/confidence-sequence-via-gambling" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>This paper considers the problem of constructing a confidence sequence, which is a sequence of confidence intervals that hold uniformly over time, for estimating the mean of bounded real-valued random processes. This paper revisits the gambling-based approach established in the recent literature from a natural \emphtwo-horse race perspective, and demonstrates new properties of the resulting algorithm induced by Cover (1991)’s universal portfolio. The main result of this paper is a new algorithm based on a mixture of lower bounds, which closely approximates the performance of Cover’s universal portfolio with constant per-round time complexity. A higher-order generalization of a lower bound on a logarithmic function in (Fan et al., 2015), which is developed as a key technique for the proposed algorithm, may be of independent interest.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICML</abbr> </div> <div id="Ryu--Xu--Erol--Bu--Zheng--Wornell2024" class="col-sm-8"> <div class="title">Operator SVD with Neural Networks via Nested Low-Rank Approximation</div> <div class="author"> <em>J. Jon Ryu</em>, <a href="https://xiangxiangxu.mit.edu/" rel="external nofollow noopener" target="_blank">Xiangxiang Xu</a>, H. S. Melichan Erol, <a href="https://buyuheng.github.io/" rel="external nofollow noopener" target="_blank">Yuheng Bu</a>, <a href="https://lizhongzheng.mit.edu/" rel="external nofollow noopener" target="_blank">Lizhong Zheng</a>, and <a href="http://allegro.mit.edu/~gww/" rel="external nofollow noopener" target="_blank">Gregory W. Wornell</a> </div> <div class="periodical"> <em>In Proc. Int. Conf. Mach. Learn. (ICML)</em> , July 2024 </div> <div class="periodical"> <a href="https://ml4physicalsciences.github.io/2023/files/NeurIPS_ML4PS_2023_225.pdf" rel="external nofollow noopener" target="_blank">An extended abstract</a> was presented at <a href="https://ml4physicalsciences.github.io/2023/" rel="external nofollow noopener" target="_blank">Machine Learning and the Physical Sciences Workshop, NeurIPS 2023</a>. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2402.03655" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openreview.net/forum?id=qESG5HaaoJ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/jongharyu/neural-svd" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/icml2024-neuralsvd-poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Computing eigenvalue decomposition (EVD) of a given linear operator, or finding its leading eigenvalues and eigenfunctions, is a fundamental task in many machine learning and scientific computing problems. For high-dimensional eigenvalue problems, training neural networks to parameterize the eigenfunctions is considered as a promising alternative to the classical numerical linear algebra techniques. This paper proposes a new optimization framework based on the low-rank approximation characterization of a truncated singular value decomposition, accompanied by new techniques called nesting for learning the top-L singular values and singular functions in the correct order. The proposed method promotes the desired orthogonality in the learned functions implicitly and efficiently via an unconstrained optimization formulation, which is easy to solve with off-the-shelf gradient-based optimization algorithms. We demonstrate the effectiveness of the proposed optimization framework for use cases in computational physics and machine learning.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICML</abbr> </div> <div id="Ryu--Wornell2024" class="col-sm-8"> <div class="title">Gambling-Based Confidence Sequences for Bounded Random Vectors</div> <div class="author"> <em>J. Jon Ryu</em>, and <a href="http://allegro.mit.edu/~gww/" rel="external nofollow noopener" target="_blank">Gregory W. Wornell</a> </div> <div class="periodical"> <em>In Proc. Int. Conf. Mach. Learn. (ICML)</em> , July 2024 </div> <div class="periodical"> Spotlight (top 3.5%) </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2402.03683" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openreview.net/forum?id=mu7Er7f9NQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/jongharyu/confidence-sequence-via-gambling" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/icml2024-gambling-poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>A confidence sequence (CS) is a sequence of confidence sets that contains a target parameter of an underlying stochastic process at any time step with high probability. This paper proposes a new approach to constructing CSs for means of bounded multivariate stochastic processes using a general gambling framework, extending the recently established coin toss framework for bounded random processes. The proposed gambling framework provides a general recipe for constructing CSs for categorical and probability-vector-valued observations, as well as for general bounded multidimensional observations through a simple reduction. This paper specifically explores the use of the mixture portfolio, akin to Cover’s universal portfolio, in the proposed framework and investigates the properties of the resulting CSs. Simulations demonstrate the tightness of these confidence sequences compared to existing methods. When applied to the sampling without-replacement setting for finite categorical data, it is shown that the resulting CS based on a universal gambling strategy is provably tighter than that of the posterior-prior ratio martingale proposed by Waudby-Smith and Ramdas.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICML</abbr> </div> <div id="Ryu--Shah--Wornell2024" class="col-sm-8"> <div class="title">A Unified View on Learning Unnormalized Distributions via Noise-Contrastive Estimation</div> <div class="author"> <em>J. Jon Ryu</em>, <a href="https://abhin-shah.github.io/" rel="external nofollow noopener" target="_blank">Abhin Shah</a>, and <a href="http://allegro.mit.edu/~gww/" rel="external nofollow noopener" target="_blank">Gregory W. Wornell</a> </div> <div class="periodical"> <em>In Proc. Int. Conf. Mach. Learn. (ICML)</em> , July 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2409.18209" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>This paper studies a family of estimators based on noise-contrastive estimation (NCE) for learning unnormalized distributions. The main contribution of this work is to provide a unified perspective on various methods for learning unnormalized distributions, which have been independently proposed and studied in separate research communities, through the lens of NCE. This unified view offers new insights into existing estimators. Specifically, for exponential families, we establish the finite-sample convergence rates of the proposed estimators under a set of regularity assumptions, most of which are new.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICML</abbr> </div> <div id="Jayashankar--Ryu--Wornell2025" class="col-sm-8"> <div class="title">Score-of-Mixture Training: Training One-Step Generative Models Made Simple</div> <div class="author"> <a href="https://tejasjayashankar.github.io/" rel="external nofollow noopener" target="_blank">Tejas Jayashankar*</a>, <em>J. Jon Ryu*</em>, and <a href="http://allegro.mit.edu/~gww/" rel="external nofollow noopener" target="_blank">Gregory W. Wornell</a> </div> <div class="periodical"> <em>In Proc. Int. Conf. Mach. Learn. (ICML)</em> , July 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2502.09609" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>We propose Score-of-Mixture Training (SMT), a novel framework for training one-step generative models by minimizing a class of divergences called the α-skew Jensen-Shannon divergence. At its core, SMT estimates the score of mixture distributions between real and fake samples across multiple noise levels. Similar to consistency models, our approach supports both training from scratch (SMT) and distillation using a pretrained diffusion model, which we call Score-of-Mixture Distillation (SMD). It is simple to implement, requires minimal hyperparameter tuning, and ensures stable training. Experiments on CIFAR-10 and ImageNet 64x64 show that SMT/SMD are competitive with and can even outperform existing methods.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> </div> <div id="Ryu--Kwon--Koppe--Jun2025" class="col-sm-8"> <div class="title">Improved Offline Contextual Bandits with Second-Order Bounds: Betting and Freezing</div> <div class="author"> <em>J. Jon Ryu</em>, <a href="https://kwonchungli.github.io/" rel="external nofollow noopener" target="_blank">Jeongyeol Kwon</a>, Benjamin Koppe, and <a href="https://kwangsungjun.github.io/" rel="external nofollow noopener" target="_blank">Kwang-Sung Jun</a> </div> <div class="periodical"> July 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2502.10826" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>We consider the off-policy selection and learning in contextual bandits where the learner aims to select or train a reward-maximizing policy using data collected by a fixed behavior policy. Our contribution is two-fold. First, we propose a novel off-policy selection method that leverages a new betting-based confidence bound applied to an inverse propensity weight sequence. Our theoretical analysis reveals that our method achieves a significantly better, variance-adaptive guarantee upon prior art. Second, we propose a novel and generic condition on the optimization objective for off-policy learning that strikes a difference balance in bias and variance. One special case that we call freezing tends to induce small variance, which is preferred in small-data regimes. Our analysis shows that they match the best existing guarantee. In our empirical study, our selection method outperforms existing methods, and freezing exhibits improved performance in small-sample regimes.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6A%6F%6E%67%68%61.%72%79%75@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=5ZYeWgcAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/jongharyu" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/jongha-jon-ryu-997ba7a7" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jongha Jon Ryu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: May 02, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?06cae41083477f121be8cd9797ad8e2f"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-3M2EMEPQ20"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-3M2EMEPQ20");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar. note&amp;#58 * indicates equal contributions. \u2020 indicates that the author ordering is alphabetical.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-talks",title:"talks",description:"",section:"Navigation",handler:()=>{window.location.href="/talks/"}},{id:"nav-repositories",title:"repositories",description:"",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-resume",title:"resume",description:"",section:"Navigation",handler:()=>{window.location.href="/resume/"}},{id:"news-two-papers-lt-a-href-quot-https-arxiv-org-abs-2502-09609-quot-gt-score-of-mixture-training-lt-a-gt-lt-strong-gt-spotlight-lt-strong-gt-top-2-6-and-lt-a-href-quot-https-arxiv-org-abs-2409-18209-quot-gt-unifying-principles-of-fitting-energy-based-models-lt-a-gt-accepted-at-icml-2025",title:"Two papers, &lt;a href=&quot;https://arxiv.org/abs/2502.09609&quot;&gt;Score-of-Mixture Training&lt;/a&gt; (&lt;strong&gt;Spotlight&lt;/strong&gt;, top 2.6%) and &lt;a href=&quot;https://arxiv.org/abs/2409.18209&quot;&gt;unifying principles of fitting energy-based models&lt;/a&gt;, accepted at ICML 2025!",description:"",section:"News"},{id:"news-new-paper-alerts-we-propose-1-a-new-simple-and-stable-training-scheme-for-one-step-generative-models-lt-a-href-quot-https-arxiv-org-abs-2502-09609-quot-gt-paper1-lt-a-gt-2-new-techniques-for-efficient-off-policy-contextual-bandits-lt-a-href-quot-https-arxiv-org-abs-2502-10826-quot-gt-paper2-lt-a-gt",title:"New paper alerts! We propose: (1) a new simple and stable training scheme for one-step generative models &lt;a href=&quot;https://arxiv.org/abs/2502.09609&quot;&gt;(paper1)&lt;/a&gt;; (2) new techniques for efficient off-policy contextual bandits &lt;a href=&quot;https://arxiv.org/abs/2502.10826&quot;&gt;(paper2)&lt;/a&gt;.",description:"",section:"News"},{id:"news-in-this-fall-i-have-given-talks-on-lt-a-href-quot-https-openreview-net-forum-id-qesg5haaoj-quot-gt-neuralsvd-lt-a-gt-at-merl-kaist-kias-and-flatiron-institute",title:"In this fall, I have given talks on &lt;a href=&quot;https://openreview.net/forum?id=qESG5HaaoJ&quot;&gt;NeuralSVD&lt;/a&gt; at MERL, KAIST, KIAS, and Flatiron Institute.",description:"",section:"News"},{id:"news-our-paper-on-lt-a-href-quot-http-arxiv-org-abs-2402-06160-quot-gt-demystifying-the-sucess-of-evidential-deep-learning-methods-lt-a-gt-got-accepted-at-neurips-2024",title:"Our paper on &lt;a href=&quot;http://arxiv.org/abs/2402.06160&quot;&gt;demystifying the sucess of evidential deep learning methods&lt;/a&gt; got accepted at NeurIPS 2024!",description:"",section:"News"},{id:"news-i-have-posted-a-substantially-revised-version-of-the-lt-a-href-quot-https-arxiv-org-abs-2202-02464-quot-gt-arxiv-preprint-lt-a-gt-on-minimax-optimal-learning-with-fixed-k-nearest-neighbors-now-including-new-results-on-density-estimation",title:"I have posted a substantially revised version of the &lt;a href=&quot;https://arxiv.org/abs/2202.02464&quot;&gt;arXiv preprint&lt;/a&gt; on minimax optimal learning with fixed-k-nearest neighbors, now including new results on density estimation.",description:"",section:"News"},{id:"news-lt-a-href-quot-http-arxiv-org-abs-2207-12382-quot-gt-one-paper-lt-a-gt-on-gambling-based-confidence-sequences-has-been-accepted-at-lt-em-gt-ieee-transactions-on-information-theory-lt-em-gt",title:"&lt;a href=&quot;http://arxiv.org/abs/2207.12382&quot;&gt;One paper&lt;/a&gt; on gambling-based confidence sequences has been accepted at &lt;em&gt;IEEE Transactions on Information Theory&lt;/em&gt;!",description:"",section:"News"},{id:"news-lt-a-href-quot-https-openreview-net-forum-id-zx27ndlfcu-quot-gt-one-paper-lt-a-gt-on-new-techniques-for-better-score-estimation-accepted-at-lt-a-href-quot-https-spigmworkshop2024-github-io-quot-gt-icml-2024-workshop-on-structured-probabilistic-inference-amp-amp-generative-modeling-lt-a-gt",title:"&lt;a href=&quot;https://openreview.net/forum?id=zX27NDlfcu&quot;&gt;One paper&lt;/a&gt; on new techniques for better score estimation accepted at &lt;a href=&quot;https://spigmworkshop2024.github.io/&quot;&gt;ICML 2024 Workshop on Structured Probabilistic Inference &amp;amp; Generative Modeling&lt;/a&gt;.",description:"",section:"News"},{id:"news-two-papers-lt-a-href-quot-https-openreview-net-forum-id-qesg5haaoj-quot-gt-neuralsvd-lt-a-gt-and-lt-a-href-quot-https-openreview-net-forum-id-mu7er7f9nq-quot-gt-time-uniform-confidence-sets-from-universal-gambling-lt-a-gt-lt-strong-gt-spotlight-lt-strong-gt-top-3-5-accepted-at-icml-2024",title:"Two papers, &lt;a href=&quot;https://openreview.net/forum?id=qESG5HaaoJ&quot;&gt;NeuralSVD&lt;/a&gt; and &lt;a href=&quot;https://openreview.net/forum?id=mu7Er7f9NQ&quot;&gt;time-uniform confidence sets from universal gambling&lt;/a&gt; (&lt;strong&gt;Spotlight&lt;/strong&gt;, top 3.5%), accepted at ICML 2024!",description:"",section:"News"},{id:"news-lt-a-href-quot-https-arxiv-org-abs-2302-08077-quot-gt-one-paper-on-learning-with-fairness-under-uncertainty-lt-a-gt-accepted-at-isit-2024",title:"&lt;a href=&quot;https://arxiv.org/abs/2302.08077&quot;&gt;One paper on learning with fairness under uncertainty&lt;/a&gt; accepted at ISIT 2024!",description:"",section:"News"},{id:"news-i-gave-a-talk-on-our-recent-work-lt-a-href-quot-https-arxiv-org-abs-2402-03655-quot-gt-neuralsvd-lt-a-gt-at-lt-a-href-quot-https-ita-ucsd-edu-quot-gt-ita-workshop-lt-a-gt",title:"I gave a talk on our recent work &lt;a href=&quot;https://arxiv.org/abs/2402.03655&quot;&gt;NeuralSVD&lt;/a&gt; at &lt;a href=&quot;https://ita.ucsd.edu&quot;&gt;ITA workshop&lt;/a&gt;.",description:"",section:"News"},{id:"news-three-preprints-about-1-lt-a-href-quot-http-arxiv-org-abs-2402-03655-quot-gt-how-to-perform-svd-using-neural-networks-lt-a-gt-2-lt-a-href-quot-http-arxiv-org-abs-2402-03683-quot-gt-how-to-construct-time-uniform-confidence-sets-for-bounded-vector-valued-processes-using-gambling-lt-a-gt-and-3-lt-a-href-quot-https-arxiv-org-abs-2402-06160-quot-gt-rethinking-the-success-of-evidential-deep-learning-lt-a-gt-have-been-posted-on-arxiv-please-reach-out-if-you-have-any-comments-or-questions-on-any-of-these",title:"Three preprints about (1) &lt;a href=&quot;http://arxiv.org/abs/2402.03655&quot;&gt;how to perform SVD using neural networks&lt;/a&gt;, (2) &lt;a href=&quot;http://arxiv.org/abs/2402.03683&quot;&gt;how to construct time-uniform confidence sets for bounded vector-valued processes using gambling&lt;/a&gt;, and (3) &lt;a href=&quot;https://arxiv.org/abs/2402.06160&quot;&gt;rethinking the success of evidential deep learning&lt;/a&gt; have been posted on arXiv. Please reach out if you have any comments or questions on any of these.",description:"",section:"News"},{id:"news-i-will-present-a-lt-a-href-quot-https-neurips-cc-virtual-2023-76253-quot-gt-poster-lt-a-gt-on-decomposing-linear-operators-with-neural-networks-at-lt-a-href-quot-https-ml4physicalsciences-github-io-2023-quot-gt-ml4ps-workshop-neurips-2023-lt-a-gt-the-extended-abstract-can-be-found-lt-a-href-quot-https-ml4physicalsciences-github-io-2023-files-neurips-ml4ps-2023-225-pdf-quot-gt-here-lt-a-gt",title:"I will present a &lt;a href=&quot;https://neurips.cc/virtual/2023/76253&quot;&gt;poster&lt;/a&gt; on decomposing linear operators with neural networks at &lt;a href=&quot;https://ml4physicalsciences.github.io/2023/&quot;&gt;ML4PS Workshop @NeurIPS 2023&lt;/a&gt;. The extended abstract can be found &lt;a href=&quot;https://ml4physicalsciences.github.io/2023/files/NeurIPS_ML4PS_2023_225.pdf&quot;&gt;here&lt;/a&gt;.",description:"",section:"News"},{id:"news-i-presented-my-recent-work-on-decomposing-linear-operators-with-neural-networks-at-lt-a-href-quot-https-calendar-csail-mit-edu-events-270823-quot-gt-mltea-talk-lt-a-gt",title:"I presented my recent work on decomposing linear operators with neural networks at &lt;a href=&quot;https://calendar.csail.mit.edu/events/270823&quot;&gt;MLTea talk&lt;/a&gt;.",description:"",section:"News"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6A%6F%6E%67%68%61.%72%79%75@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=5ZYeWgcAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/jongharyu","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/jongha-jon-ryu-997ba7a7","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>